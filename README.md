# Data-Normalization-Min-Max-Normalization
Data Normalization

Because of the broad range of variability present in raw data, the trained model in machine learning cannot function correctly unless the data are first subjected to some kind of data normalization. If you don't normalize the data, the model will be dominated by the variables that utilize a bigger scale, which will have a negative impact on the model's performance. Normalizing the data. Because of this, normalizing the data is an absolute need. You are able to standardize the range of independent data by using the Min-Max Scaling. In the realm of data processing, this phase, which is often carried out during the data preparation stage, is also known by the name data normalization.

In this project, we'll be using a straightforward data set from Kaggle's Height Weight challenge. It only includes the heights, measured in inches, and weights, measured in pounds, of 25,000 unique persons who are at least 18 years old. This dataset may be used to construct a model that is capable of making accurate predictions about the heights or weights of humans.
